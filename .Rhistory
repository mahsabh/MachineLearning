?I
?mtcars
?hat
?hatvalues
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
model<-lm(y~x)
hatvalues(model)
x5
x[5]
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
model<-lm(y~x)
hatvalues(model)
dfbeta(model)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
model<-lm(y~x)
influence.measures(model)
hatvalues(model)
plot(x,y)
?incCount
2.Quantifying how different is the MPG between automatic and manual transmissions?
head(mtcars)
?mtcars
mtcars
full<-lm (mpg ~ ., data=mtcars)
step(full, data=mtcars, direction="backward")
x<-c(140,138,150,148,135)
y<-c(132,135,151,146,130)
x-y
?t.test
?power.t.test
pnorm(-0.855,lower.tail=FALSE)
pnorm(-0.86,lower.tail=FALSE)
pnorm(-0.90,lower.tail=FALSE)
?pnorm
qnorm(0.90,lower.tail=FALSE)
pnorm(-1.28,lower.tail=FALSE)
?pt
?pnorm
?t.test
?z.test
xbar= 44
mu0= 42.04
sigma= 12
n= 288
z=(xbar-mu0)/(sigma/sqrt(n))
z
pval=2*pnorm(z)
pval
xbar= 42.04
mu0= 44
sigma= 12
n= 288
z=(xbar-mu0)/(sigma/sqrt(n))
z
pval=2*pnorm(z)
pval
xbar= 42.04
mu0= 44
sigma= 12
n= 288
z=(xbar-mu0)/(sigma/sqrt(n))
z
pval=2*pnorm(z)
pval
pnorm(z)
xbar= 44
mu0= 42.04
sigma= 12
n= 288
z=(xbar-mu0)/(sigma/sqrt(n))
z
pval=2*pnorm(z)
pval
xbar= 42.04
mu0= 44
sigma= 12
n= 288
z=(xbar-mu0)/(sigma/sqrt(n))
z
pval=2*pnorm(z)
pval
sqrt(0.804)
2*pnorm(-4.46)
dataset(mtcars)
data(mtcars)
head(mtcars)
mean<-mean(mtcars$mpg)
mean
st<-st(mtcars$mpg)
?sd
sd<-sd(mtcars$mpg)
sd
nrow(mtcars)
?solve
qnorm(0.05)
?qnorm
qnorm(0.025)
qnorm(0.95)
qnorm(0.975)
pnorm(0.95)
qnorm(0.95)
z=1.644=(mu-mean)/(sd/sqrt(32))
1.644*sd/sqrt(32)+mean
mean-1.644*sd/sqrt(32)
m4 <- mtcars$mpg[mtcars$cyl == 4]
m6 <- mtcars$mpg[mtcars$cyl == 6]
p <- t.test(m4, m6, paired = FALSE, alternative="two.sided", var.equal=FALSE)$p.value
p
m4 <- mtcars$mpg[mtcars$cyl == 4]
m6 <- mtcars$mpg[mtcars$cyl == 6]
t.test(m4, m6, paired = FALSE, alternative="two.sided", var.equal=FALSE)$p.value
m4 <- mtcars$mpg[mtcars$cyl == 4]
m6 <- mtcars$mpg[mtcars$cyl == 6]
t.test(m4, m6, paired = FALSE, alternative="two.sided", var.equal=FALSE)
t.test
?t.test
x<-c(140,138,150,148,135)
y<-c(132,135,151,146,130)
t.test(x, y, paired = FALSE, alternative="two.sided", var.equal=FALSE)
t.test(x, y, paired = FALSE, alternative=c("two.sided","less"), var.equal=FALSE)
t.test(x, y, paired = FALSE, alternative="less", var.equal=FALSE)
mean<-3.0
sigma<-1.1
n<-100
z<-qnorm(0.975)
z
qnorm(0.95)
(x-mean)sqrt(n)/sigma
(x-mean)*sqrt(n)/sigma
mean-z*sigma/sqrt(n)
mean+z*sigma/sqrt(n)
mean<-1100
sigma<-30
n<-9
mean+z*sigma/sqrt(n)
mean-z*sigma/sqrt(n)
t<-qt5(0.95,df=8,lower.tail=TRUE)
t<-qt(0.95,df=8,lower.tail=TRUE)
t
t<-qt(0.95,df=8,lower.tail=FALSE)
t
t<-qt(0.975,df=8,lower.tail=TRUE)
t
t<-qt(0.975,df=8,lower.tail=FALSE)
t
t<-qt(0.975,df=8,lower.tail=TRUE)
t
mean+t*sigma/sqrt(n)
mean-t*sigma/sqrt(n)
x<-c(140,138,150,148,135)
y<-c(132,135,151,146,130)
t.test(x, y, paired = FALSE, alternative="less", var.equal=FALSE)
t.test(x, y, paired = FALSE, alternative="two-sided", var.equal=FALSE)
t.test(x, y, paired = FALSE, alternative="two.sided", var.equal=FALSE)
t.test(y, x, paired = FALSE, alternative="two.sided", var.equal=FALSE)
t.test(x, y, paired = FALSE, alternative="two.sided", var.equal=FALSE)
t.test(x, y, paired = FALSE, alternative="less", var.equal=FALSE,conf.level= 0.975)
t.test(x, y, paired = FALSE, alternative="less", var.equal=FALSE,conf.level= 0.95)
t.test(y-x)
pbinom(3, prob = .5, size = 4, lower.tail = FALSE)
pbinom(4, prob = .5, size = 4, lower.tail = FALSE)
pbinom(4, prob = .5, size = 4, lower.tail = TRUE)
pbinom(3, prob = .5, size = 4, lower.tail = TRUE)
pbinom(3, prob = .5, size = 4, lower.tail = FALSE)
pbinom(2, prob = .5, size = 4, lower.tail = FALSE)
pbinom(74, prob = .5, size = 100, lower.tail = FALSE)
pbinom(73, prob = .5, size = 4, lower.tail = FALSE)
pbinom(3, prob = .5, size = 4, lower.tail = FALSE)
?z.test
qnorm(0.75)
?qnorm
dnorm(0.75)
1-qnorm(0.75)
pnorm(o.75, lower.tail=FALSE)
pnorm(o.75)
pnorm(0.75, lower.tail=FALSE)
?ppois
ppois(10, 1787*0.01, lower.tail = TRUE)
ppois(10, 1787*0.01, lower.tail = FALSE)
ppois(10, 1787*0.01, lower.tail = TRUE)
sigma<-sqrt(0.75*0.25/100)
sigma
z<-(0.5-0.75)/sigma
z
pnorm(z)
qnorm(z)
dnorm(z)
1-pnorm(z)
pbinom(3, prob = .5, size = 4, lower.tail = FALSE)
?pnorm
z<-(0.75-0.5)/sigma
z
pnorm(z)
1-pnorm(z)
z<-(0.5-0.75)/sqrt(0.75*0.25/1000)
z
pnorm(z)
z<-(0.5-0.75)/sqrt(0.75*0.25/4)
pnorm(z)
z
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("caret")
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
head(AlzheimerDisease)
head("AlzheimerDisease")
head(AlzheimerDisease)
head(AlzheimerDisease)
install.packages(caret)
install.packages("caret")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
head(AlzheimerDisease)
head("AlzheimerDisease")
head(AlzheimerDisease)
library(caret)
data(AlzheimerDisease)
AlzheimerDisease
library(caret)
data(AlzheimerDisease)
data(AlzheimerDisease)
dim(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
head(adData)
dim(adData)
dim(training)
dim(testing)
names(adData)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
dim(adData)
dim(training)
dim(testing)
?data.frame
class(AlzheimerDisease)
diagnosis
predictors
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
class(inTrain)
inTrain
CompressiveStrength
mixtures$CompressiveStrength
mixtures
head(mixtures)
names(mixtures)
install.packages("Hmisc ")
?cut2
install.packages("Hmisc")
training
head(training)
Plot(mixtures$CompressiveStrength)
plot(mixtures$CompressiveStrength)
plot(training$CompressiveStrength)
plot(testing$CompressiveStrength)
plot(training$CompressiveStrength)
?cut2
?cut2
?Cut2
install.packages("Hmisc")
?cut2
??cut2
names(training)
plot(training$FlyAsh)
plot(training$Age)
plot(training$CompressiveStrength)
plot(training$Cement)
plot(training$BlastFurnaceSlag)
plot(training$Water)
plot(training$Superplasticizer)
plot(training$CoarseAggregate)
plot(training$FineAggregate)
plot(training$Age)
cut<-cut2(training$CompressiveStrength)
cut<-Cut2(training$CompressiveStrength)
cut<-cut(training$CompressiveStrength)
?cut
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
names(mixture)
names(mixtures)
plot(mixtures$Superplasticizer)
hist(mixtures$Superplasticizer)
mixtures$Superplasticizer
hist(log(mixtures$Superplasticizer))
hist(mixtures$Superplasticizer)
log(mixtures$Superplasticizer)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
adData
head(adData)
names(adData)
adData[1,]
adData[,1]
?grep
trainingIL<-adData[,grep("IL", names(adData))]
names(trainingIL)
trainingIL<-adData[,grep("^IL", names(adData))]
names(trainingIL)
trainingIL[,-13]
preProc9 <- preProcess(trainingIL[,-12],method="pca",tresh=0.9)
preProc9
?preProcess
preProc9 <- preProcess(trainingIL[,-12],method="pca",tresh= 0.90)
preProc9
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingIL<-adData[,grep("^IL", names(adData))]
preProc9 <- preProcess(trainingIL[,-12],method="pca",tresh= 0.90)
trainPC9 <- predict(preProc9,trainingIL[,-12])
modelFit9 <- train(trainingIL$diagnosis ~ .,method="glm",data=trainPC9)
modelFit9
summary(modelFit9$finalModel)
confusionMatrix(trainingIL$diagnosis,predict(modelFit9,trainPC9))
head(preProc9)
names(preProc9)
names(trainPC9)
names(trainingIL)
setwd("C:/Users/baghaei-heravi.mahsa/Desktop/R-Save Files/Machine Learning/Project")
data_training<-read.csv("./pml-training.csv")
data_testing<-read.csv("./pml-testing.csv")
library(AppliedPredictiveModeling)
library(caret)
dim(data_training)
set.seed(124)
##get rid of empty cells
emptyCells<-which(data_training=="",arr.ind = TRUE)
data_training[emptyCells]<- NA
##get rid of NA
new_data_training <- data.frame(row.names=1:19622)
x<-c()
for (i in 1:ncol(data_training)){
count <- length(data_training[data_training[,i]=="NA",i])
if (count>18000) {
x<-append(x,i)
}
}
new_data_training<-data_training[,-x]
dim(new_data_training)
class(new_data_training)
names(new_data_training)
new_data_training1<-new_data_training[,-c(1,2,5)]
names(new_data_training1)
transparentTheme(trans = .4)
featurePlot(x = new_data_training1[,c(1:10)] , y = new_data_training1$classe , plot="pairs" )
featurePlot(x = new_data_training1[,c(1:5)] , y = new_data_training1$classe , plot="pairs" )
prComp<-prcomp(new_data_training1[,-57])
prComp<-prcomp(log10(new_data_training1[,-57]+1)
prComp<-prcomp(log10(new_data_training1[,-57]+1))
?log10
prComp<-prcomp(log(new_data_training1[,-57]+1))
y<-c()
for (i in 1:56){
if (class(new_data_training1[,i])=="integer" | class(new_data_training1[,i])=="numeric"){
y<-append(y,i)
}
}
new_data_training2<-new_data_training1[,y]
dim(new_data_training2)
names(new_data_training2)
names(new_data_training1)
y<-c(57)
for (i in 1:56){
if (class(new_data_training1[,i])=="integer" | class(new_data_training1[,i])=="numeric"){
y<-append(y,i)
}
}
new_data_training2<-new_data_training1[,y]
dim(new_data_training2)
names(new_data_training2)
prComp<-prcomp(log(new_data_training2[,-57]+1))
prComp<-prcomp(log(new_data_training2[,-1]+1))
warnings()
prComp<-prcomp(log(new_data_training2[,-1]+2))
prComp<-prcomp(new_data_training2[,-1])
prComp
data_training<-read.csv("./pml-training.csv")
data_testing<-read.csv("./pml-testing.csv")
library(AppliedPredictiveModeling)
library(caret)
dim(data_training)
set.seed(124)
##get rid of empty cells
emptyCells<-which(data_training=="",arr.ind = TRUE)
data_training[emptyCells]<- NA
##get rid of NA
new_data_training <- data.frame(row.names=1:19622)
x<-c()
for (i in 1:ncol(data_training)){
count <- length(data_training[data_training[,i]=="NA",i])
if (count>18000) {
x<-append(x,i)
}
}
new_data_training<-data_training[,-x]
dim(new_data_training)
class(new_data_training)
names(new_data_training)
new_data_training1<-new_data_training[,-c(1,2,5,6)]
names(new_data_training1)
prComp<-prcomp(new_data_training[,-56])
prComp<-prcomp(new_data_training1[,-56])
dim(prComp)
prComp$rotation
prComp<-prcomp(log(new_data_training1[,-56]+1))
install.packages("doParallel")
library(doParallel)
cl <- makeCluster(detectCores())
registerDoParallel(cl)
?preProcess
preProc <- preProcess(new_data_training1[,-56],method="pca",thresh = 0.95)
preProc
trainTransformed <- predict(preProc, new_data_training1)
trainTransformed
names(new_data_training1)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
dim(training)
## find correlated variables
preProc <- preProcess(training[,-56],method="pca",thresh = 0.95)
trainTransformed <- predict(preProc, training)
names(new_data_training1)
## cross validation
inTrain <- createDataPartition(y=new_data_training1$classe,
p=0.80, list=FALSE)
training <- new_data_training1[inTrain,]
testing <- new_data_training1[-inTrain,]
dim(training)
## find correlated variables
preProc <- preProcess(training[,-56],method="pca",thresh = 0.95)
trainTransformed <- predict(preProc, training)
preProc <- preProcess(training[,-56],method="pca",thresh = 0.95)
preProc
trainTransformed <- predict(preProc, training[,-56])
trainTransformed
dim(trainTransformed)
names(trainTransformed)
preProc <- preProcess(training[,-56],method="pca",thresh = 0.98)
trainTransformed <- predict(preProc, training[,-56])
dim(trainTransformed)
modelFit <- train(training$classe ~ ., data = trainTransformed, method="rf")
library(randomForest)
preProc <- preProcess(training[,-56],method="pca",thresh = 0.98)
trainTransformed <- predict(preProc, training[,-56])
dim(trainTransformed)
modelFit <- train(training$classe ~ ., data = trainTransformed, method="rf")
new_data_testing<-data_testing[,-x]
dim(new_data_testing)
class(new_data_testing)
names(new_data_testing)
new_data_testing<-data_testing[,-x]
dim(new_data_testing)
class(new_data_testing)
names(new_data_testing)
new_data_testing1<-new_data_testing[,-c(1,2,5,6)]
names(new_data_testing1)
names(new_data_training1)
predictions <- predict(modelFit,newdata=new_data_testing1)
?confusionMatrix
testTransformed <- predict(preProc,testing[,-56])
confusionMatrix(testing$classe,predict(modelFit,testTransformed))
preProc <- preProcess(training[,-56],method="pca",thresh = 0.95)
preProc
trainTransformed <- predict(preProc, training[,-56])
dim(trainTransformed)
##M<-abs(cor(is.numeric(data_training[,-160])))
##diag(M)<-0
##which(M>0.8, arr.ind=T)
```
```{r , cache=TRUE}
##model
library(randomForest)
modelFit <- train(training$classe ~ ., data = trainTransformed, method="rf")
?predict
predicts
